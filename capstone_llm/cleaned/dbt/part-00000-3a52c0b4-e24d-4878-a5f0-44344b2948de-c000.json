{"title":"will DBT support temp table creation like create table #temp1 as select * from tab1 or it works only CTE way","question_body":"<p>I found out a way to handle the temp tables in DBT, write all those in pre-hook and call the final temp table in the outside of the pre-hook, tested and is working fine, able to reduce the code running time from more than 20 mins to 1 min. But I see one problem that we can't see the lineage graph in the DBT documents.\nIs there any way to handle the temp tables other than pre-hook and with lineage in Docs?</p>\n","answer_body":"<p>You're right in thinking that dbt does not support temporary tables. That's because temporary tables only persist in a single session, and dbt opens one connection/session per thread. Therefore any temporary tables created on one thread would not be visible to a model running on a different thread.</p>\n<p>It sounds like CTEs are a performance drag for you though — out of interest, which warehouse are you using?</p>\n<p>You've identified two workarounds, and there's another one worth discussing:</p>\n<p><strong>Option 1: Materialize your model as CTEs using the <code>ephemeral</code> materialization (<a href=\"https://docs.getdbt.com/docs/building-a-dbt-project/building-models/materializations/#ephemeral\" rel=\"noreferrer\">docs</a>)</strong></p>\n<p><em>Pros:</em></p>\n<ul>\n<li>The models show up in the lineage graph</li>\n<li>You can re-use these transformations in multiple downstream models by <code>ref</code>-ing them</li>\n<li>You can test and document these models</li>\n</ul>\n<p><em>Cons:</em></p>\n<ul>\n<li>At some point there is a performance degradation with too many stacked CTEs (especially on older versions of postgres, where CTEs are an optimization fence)</li>\n<li>Compiled SQL can be harder to debug</li>\n</ul>\n<p><strong>Option 2: Use pre-hooks to create temp tables</strong></p>\n<p>I would generally recommend against this — you can't test or document your models, and they won't be in the lineage graph (as you've noted).</p>\n<p><strong>Option 3: Materialize these models as tables in a separate schema, and drop the schema at the end of a run</strong></p>\n<p>I think Michael's suggestion is a good one! I'd tweak it just a little bit:</p>\n<ol>\n<li>Use the <a href=\"https://docs.getdbt.com/reference/resource-configs/schema/\" rel=\"noreferrer\">schema</a> config to materialize a model in a separate schema</li>\n</ol>\n<pre><code>{{ config(\n  materialized='table',\n  schema='my_temporary_schema'\n) }}\n</code></pre>\n<ol start=\"2\">\n<li>Then, at the end of a run, use an <code>on-run-end</code> hook (<a href=\"https://docs.getdbt.com/reference/project-configs/on-run-start-on-run-end/\" rel=\"noreferrer\">docs</a>) to drop that schema — in your <code>dbt_project.yml</code>:</li>\n</ol>\n<pre><code>on-run-end: &quot;drop schema my_temporary_schema cascade&quot;\n</code></pre>\n<p><em>Pros:</em></p>\n<ul>\n<li>All the benefits of Option 1</li>\n<li>Sounds like it might be more performant than using CTEs</li>\n</ul>\n<p><em>Cons:</em></p>\n<ul>\n<li>Make sure you don't have any dependent views on top of that schema! They might get dropped when you run a <code>drop cascade</code> command! This introduces fragility into your project!</li>\n</ul>\n"}
